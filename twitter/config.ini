###########################
# twitter config settings #
###########################


[MAIN]
log_level           = DEBUG
print_to_console    = True
# choose store between file, pandas or sql
store_type          = sql
# save all tweets in one file\table (all_tweets) or split them in different files\tables according to hashtag
store_together      = True
path_to_data        = data/raw/
process_data        = data/processed/
path_to_plots       = data/plots/
df_buffer_size      = 100


[SQL]
db_name             = Bayernwahl.sqlite
default_table       = All_Tweets


[TWITTER]
# specify the hashtag for which tweets are streamed
hashtag             = #AFD, #afd, #AfD, #CDU,, #csu, #cdu #CSU, #Bayern, #ltwby, #LTW18, #LtwBayern, #Bayernwahl, #SÃ¶der, #Seehofer, #ltwBY18, #merkel, #ltwby2018
language            = de

# turn use_most_trending True will skip the above hashtag and automatically choose the most trending tweets
use_most_trending   = False
country             = US
town                = None

# specify which attributes to store
include_attributes  = created_at, id_str, text, user, place, sentiment
user_attributes     = name, screen_name, location, followers_count, friends_count, id_str
# program is adding all attributes in one list (user_id_str for id_str)
# coordinates are always None...


[DELETION]
# limited to 100 by API, see http://docs.tweepy.org/en/v3.5.0/api.html#API.statuses_lookup
batch_size          = 100
file_name           = deleted_tweets.json
# time interval, checking every X minutes
checking_interval   = 10
# pass this info as nested dict to the insert function and manually add the last seen time stamp of your system
include_attributes  = id_str, retweet_count, favorite_count, user
user_attributes     = followers_count, friends_count, favourites_count, id_str
